{
    "llm_config": {
        "model_name": "gpt-4o",
        "verbose": true
    },
    "max_iterations": 2000,
    "max_execution_seconds": 600,
    "commondefs": {
        "replacement_strings": {
            "instructions_prefix": """
            You are an expert Python Data Analysis assistant. 
            You must only reply to questions related to Data Analysis! Do not respond to any questions
            that are off-topic or unrelated to this!
            Do not try to help for personal matters.
            Do not mention what you can NOT do. Only mention what you can do.
            """,
        },
        "replacement_values": {
            "code_snippet_def": {
                "type": "string",
                "description": """
The unaltered code to work on, in its entirety.
"""
            }
        }
    },
    "tools": [
        # These tool definitions do not have to be in any particular order
        # How they are linked and call each other is defined within their
        # own specs.  This could be a graph, potentially even with cycles.

        # This first guy is the "Front Man".  He is identified as such because
        # he is the only one with no parameters in his function definition,
        # and therefore he needs to talk to the outside world to get things rolling.
        {
            "name": "analytics_agent",

            # Note that there are no parameters defined for this guy's "function" key.
            # This is the primary way to identify this tool as a front-man,
            # distinguishing it from the rest of the tools.

            "function": {

                # When there are no function parameters to the front-man,
                # its description acts as an initial prompt.

                "description": """
Perform Data Analysis.
"""
            },

            "instructions": """
{instructions_prefix}
You are the top-level agent responsible for data analysis. 
You must complete these steps in order to help a user with data analysis.
    1. Call the get_input_file tool to get the input file. 
        - The resulting output from this tool is a JSON dictionary with key as "input_path" and value as the absolute file path.

    2. Pass any problem description comments, and user inquiry along with the JSON dictionary output absolute file path to the 
    generate_analysis_code tool for generating code to create a plot or dataframe using the data present at input_path.
        - The output from this tool would be a JSON dictionary with key as "code_snippet" 
        and value that is code snippet in a single string.
    
    3. Pass the above "code_snippet" to the code_validator tool.  
    - The outputs from this tool would be a JSON dictionary that may have one of the keys:
        - "code_snippet": If present, this means the code snippet was good. And we can proceed to step 4 to generate an output.
        - "error": If present, this will describe any error that might
                have arisen during the testing of the code. Using this error message as context, retry generate_analysis_code from step 2 above.
    
    4. Pass the code_snippet into the analytics_output_generator tool.
        - This code must be passed verbatim and in its entirety.
        - The output of this tool will be a URL string that will be known as 'output_url'.


    5. Open the object at the url generated from this tool.

    6. Return either:
        a.  the output of the "analytics_output" dictionary from the plot_creation tool
            as a JSON dictionary   or
        b.  Any error message, which will always be preceded by the error marker 'Error:'
        Specifically, do not make up a analytics_output dictionary in the case of an error.
""",
            "tools": ["get_input_file", "generate_analysis_code", "code_validator"]
        },

        {
            "name": "generate_analysis_code",

            "function": {

                "description": """
Generate analysis or plotting code for a given CSV and return a plot or description.
"""
                "parameters": {
                    "type": "object",
                    "properties": {
                        "inquiry": {
                            "type": "string",
                            "description": "The inquiry"
                        },
                        "input_path": {
                            "type": "string",
                            "description": "File path obtained from the user."
                        },
                        "sp_imports": {
                            "type": "string",
                             "enum": ['matplotlib', 'seaborn'],
                            "description": """
A list of special imports that may be used in generating code.
                            """
                        },
                        "com_imports": {
                            "type": "string",
                             "enum": ['base64', 'json', 'pandas', 'numpy', 'datetime', 'uuid'],
                            "description": """
A list of common imports that may be used in generating code.
                            """
                        }
                    },
                    "required": ["inquiry", "input_path", "sp_imports", "com_imports"]
                }
            },

            "instructions": """
When you receive an inquiry, you will follow these steps:
Call the data_describer tool to get a description of the columns in the data.
1. Ask user for what they would like to analyze in the. Classify the user input query into one of the following types:
    'plot' -   If user asks for generating a plot, chart or visualization of any kind.
    'description'  -   If user asks to describe the data or any aspect of it.
    'dataframe' - If user asks to provide a dataframe or part of a dataframe as a result.

2. Do not deviate from the columns in the given dataset. Do one of the following based on the user query:
If user query is classified as 'description':
    - Without importing the sp_imports packages, provide a detailed response as plain text.
    - Use the outputs from data_describer tool if required.

If user query is classified as 'dataframe':
    - Write python code for the input_path using com_imports packages, to provide the required dataframe or part of dataframe
        as asked: inquiry.
    - Do not write any text explanation except the code and the code should run directly without errors.
    - This code would be known as code_snippet.

If user query is classified as 'plot':
    - Write python code for the input input_path, using com_imports and sp_imports packages, to: inquiry.
    -  "For matplotlib or seaborn code, add functionality to save the plot with a uuid. "
        "# Save the plot\noutput_path = 'output_plot_' + str(uuid.uuid4()) + '.png' \nplt.savefig(output_path)\nplt.show()"
    - Do not write any text explanation except the code and the code should run directly without errors.
    - This code would be known as "code_snippet".

3. In the end, return a JSON dictionary with key as "code_snippet" and value that is the generated code snippet 
    in a single string.
    - Take special care to preserve all formatting of data generator code,
    keeping all white spaces and text indentation in the original form.
""",
            "tools": ["data_describer"]
            "command": "Return the code snippet or description for the given data analysis task."
        },

        {
            "name": "get_input_file",
            "function": {
                "description": """
Returns the absolute path to the input CSV.
You MUST call this tool to get the path of the input CSV file.
                """,
                "parameters": {
                    "type": "object",
                    "properties": {
                        "input_path": {
                            "type": "string",
                            "description": "The absolute path of the CSV being analyzed."
                        },
                    },
                    "required": ["input_path"]
                    }
            },
            "class": "get_input_file.GetInputFile",
            "command": "Return the absolute URL of the input file path."
        },

        {
            "name": "code_validator",
            "function": {
                "description": """
Tests a given code snippet and reports if there are any errors in executing it. Return either the code or an error.
"""
                "parameters": {
                    "type": "object",
                    "properties": {
                        "code_snippet": "code_snippet_def",
                    },
                    "required": ["code_snippet"]
                    }
                }
            "class": "code_validator.CodeValidator",
            "command": "Return the code snippet or return error message if code validation fails."
        },
        {
            "name": "data_describer",
            "function": {
                "description": """
Given a URL to a csv data file, this function will return a description
characterizing the file's data in JSON dictionary form,
which includes the following keys:
    "data_description" - a JSON dictionary describing the high-level characteristics of all the columns.
""",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "input_path": {
                            "type": "string",
                            "description": "A URL describing the location of where the csv data file to be read can be found."
                        },
                    },
                    "required": ["input_path"]
                }
            },
            "class": "data_describer.DataDescriber",
            "command": "Return data description of the given data."
        },
        {
            "name": "analytics_output_generator",
            "function": {
                "description": """
Runs a given code snippet in order to generate a synthesized data file
for a project being processed.
""",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "project_name": {
                            "type": "string",
                            "description": "The name of the project being processed."
                        },
                        "code_snippet": {
                            "type": "string",
                            "description": """
A snippet of code to run that will generate create the synthesized data file.
This code must come verbatim from the Opportunity Finder results.
"""
                        }
                    },
                    "required": ["project_name", "code_snippet"]
                }
            },
            "class": "analytics_output_generator.AnalyticsOutputGenerator",
            "command": "Create the synthetic data file and return its URL or return error message if data file generation fails."
        },
    ]
}
